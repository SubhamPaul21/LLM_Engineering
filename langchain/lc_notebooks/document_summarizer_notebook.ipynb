{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6309321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba7152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text splitter, load PDF documents and split it\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "loader = PyPDFLoader(\n",
    "    \"D:\\\\Artificial Intelligence\\\\LLM_Engineering\\\\langchain\\\\files\\\\PEGAI_CH1.pdf\",\n",
    ")\n",
    "pages = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c94c44e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CHAPTER 1 The Five Principles of Prompting Prompt engineering is the process of discovering prompts that reliably yield useful or desired results. A prompt is the input you provide, typically text, when interfacing with an AI model like ChatGPT or Midjourney. The prompt serves as a set of instructions the model uses to predict the desired response: text from large language models  (LLMs) like ChatGPT, or images from diffusion models like Midjourney. Here is a simple example of a prompt input for a product name generator (inspired by one of OpenAI’s examples), and the resulting output from ChatGPT. Input: Can I have a list of product names for a pair of shoes that can fit any foot size? Output: Certainly! Here's a list of product names for a pair of shoes that can fit any foot size: UniFit SoleStrides FlexiSize All-Fit Shoes OmniFit FootFlex ... AnyStep AdaptiWalkers FlexiRange UniversalSteps PerfectGlide MultiFit Shoes 1\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[4].page_content.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe8a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7,\n",
    "    reasoning_effort=\"medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26bda6b",
   "metadata": {},
   "source": [
    "##### Summarization using HumanMessage and StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Summarize the following text: \"\n",
    "        + pages[4].page_content.replace(\"\\n\", \" \"),\n",
    "    )\n",
    "]\n",
    "\n",
    "chain = llm | StrOutputParser()\n",
    "output = chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06603ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of Chapter 1 – The Five Principles of Prompting**\n",
       "\n",
       "Prompt engineering involves crafting inputs (prompts) that consistently produce useful results from AI models such as ChatGPT (text) or Midjourney (images). A prompt acts as a set of instructions guiding the model’s prediction. For example, asking “Can I have a list of product names for a pair of shoes that can fit any foot size?” yields a concise list of creative shoe‑name suggestions from ChatGPT. The chapter introduces this concept as the foundation for the five guiding principles that will follow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c56b9",
   "metadata": {},
   "source": [
    "##### Summarization using LangChain built-in load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2da0669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "summarizer_chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = summarizer_chain.invoke(pages[4:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8184de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt engineering** is the practice of designing clear, structured prompts that steer AI models (e.g., ChatGPT, Midjourney) toward reliable, high‑quality outputs. A simple “naïve” prompt can work for occasional queries, but production‑level use demands more rigor to avoid vague directions, unformatted results, biased or generic answers, lack of evaluation, and overloaded prompts.\n",
       "\n",
       "The chapter proposes **Five universal prompting principles** that solve these issues:\n",
       "\n",
       "1. **Give Direction** – Explicitly state the desired style, persona, or tone.  \n",
       "2. **Specify Format** – Define the exact response structure (e.g., comma‑separated list).  \n",
       "3. **Provide Examples** – Include correct input‑output pairs to guide the model.  \n",
       "4. **Evaluate Quality** – Set metrics, rate outputs, and identify error patterns.  \n",
       "5. **Divide Labor** – Break complex tasks into sequential, specialized subtasks.\n",
       "\n",
       "Applying these principles—by adding style cues, a fixed output format, and exemplar names—turns a basic product‑name prompt into a dependable, cost‑effective tool that can be iterated on with user feedback. The guidelines are model‑agnostic, work for both text and image generation, and align with OpenAI’s Prompt Engineering Guide."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.get(\"output_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a57a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
