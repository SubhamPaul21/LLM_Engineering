{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Replace with the YouTube handle or channel ID (not the video ID)\n",
    "channel_handle = \"@AkshatZayn\"  # or use \"UC_x5XG1OV2P6uZZ5FSM9Ttw\"\n",
    "url = f\"https://www.youtube.com/{channel_handle}/community\"\n",
    "\n",
    "# Set up Selenium Chrome driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--log-level=3\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Scroll to load more posts (You can increase the range for more content)\n",
    "for _ in range(3):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Get post elements\n",
    "posts = driver.find_elements(By.XPATH, '//ytd-backstage-post-renderer')\n",
    "\n",
    "print(f\"Found {len(posts)} community posts.\")\n",
    "\n",
    "for idx, post in enumerate(posts, start=1):\n",
    "    try:\n",
    "        content = post.find_element(By.ID, 'content-text').text\n",
    "        print(f\"\\nPost #{idx}:\\n{content}\\n{'-'*40}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nPost #{idx}:\\n[Could not extract text content]\")\n",
    "        continue\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Path to your Chrome user profile (replace accordingly)\n",
    "# This uses your already logged-in session\n",
    "profile_path = \"C:\\\\Users\\\\subha\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f\"--user-data-dir={profile_path}\")\n",
    "options.add_argument(\"--profile-directory=Default\")  # or \"Profile 1\", \"Profile 2\" etc.\n",
    "options.add_argument(\"--start-maximized\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Go to Community tab of the channel\n",
    "channel_handle = \"@AkshatZayn\"\n",
    "url = f\"https://www.youtube.com/{channel_handle}/community\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll to load more posts\n",
    "for _ in range(3):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Extract posts\n",
    "posts = driver.find_elements(By.XPATH, '//ytd-backstage-post-renderer')\n",
    "\n",
    "print(f\"Found {len(posts)} community posts (including members-only if you're authorized).\")\n",
    "\n",
    "for idx, post in enumerate(posts, start=1):\n",
    "    try:\n",
    "        content = post.find_element(By.ID, 'content-text').text\n",
    "        print(f\"\\nPost #{idx}:\\n{content}\\n{'-'*40}\")\n",
    "    except Exception:\n",
    "        print(f\"\\nPost #{idx}:\\n[Content not accessible or text missing]\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import random\n",
    "import time\n",
    "\n",
    "def human_delay(base=2.0):\n",
    "    time.sleep(base + random.uniform(0.3, 1.5))\n",
    "\n",
    "\n",
    "# Initialize WebDriver (make sure you have the correct ChromeDriver installed)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--log-level=3\")\n",
    "\n",
    "# Define search parameters\n",
    "keyword = \"AI Software Engineer\"\n",
    "location = \"India\"\n",
    "\n",
    "# Open Indeed and search\n",
    "driver.get(\"https://www.indeed.com\")\n",
    "\n",
    "# Wait for page to load\n",
    "time.sleep(3)\n",
    "\n",
    "close_button = driver.find_element(By.ID, \"onetrust-accept-btn-handler\")\n",
    "close_button.click()\n",
    "\n",
    "# Enter the job keyword\n",
    "what_input = driver.find_element(By.ID, \"text-input-what\")\n",
    "what_input.clear()\n",
    "what_input.send_keys(keyword)\n",
    "human_delay()\n",
    "\n",
    "# Enter the job location\n",
    "where_input = driver.find_element(By.ID, \"text-input-where\")\n",
    "where_input.clear()\n",
    "where_input.send_keys(location)\n",
    "where_input.send_keys(Keys.RETURN)\n",
    "human_delay()\n",
    "\n",
    "# Wait for results to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Scrape job results\n",
    "job_cards = driver.find_elements(By.CSS_SELECTOR, \".job_seen_beacon\")\n",
    "human_delay()\n",
    "\n",
    "jobs = []\n",
    "for card in job_cards:\n",
    "    try:\n",
    "        title = card.find_element(By.CSS_SELECTOR, \"h2.jobTitle\").text\n",
    "        company = card.find_element(By.CSS_SELECTOR, \"span.companyName\").text\n",
    "        location = card.find_element(By.CSS_SELECTOR, \"div.companyLocation\").text\n",
    "        link = card.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "\n",
    "        human_delay()\n",
    "        \n",
    "        jobs.append({\n",
    "            \"title\": title,\n",
    "            \"company\": company,\n",
    "            \"location\": location,\n",
    "            \"link\": link\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(\"Skipping a job card due to error:\", e)\n",
    "\n",
    "# Print job results\n",
    "for job in jobs:\n",
    "    print(job)\n",
    "\n",
    "# Close browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb95a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import Client\n",
    "\n",
    "serpapi = Client(api_key=\"\")\n",
    "\n",
    "params = {\n",
    "  \"engine\": \"google_jobs\",\n",
    "  \"google_domain\": \"google.co.in\",\n",
    "  \"q\": \"Software Engineer\",\n",
    "  \"hl\": \"en\",\n",
    "  \"gl\": \"in\",\n",
    "  \"location\": \"India\",\n",
    "  \"no_cache\": \"true\"\n",
    "}\n",
    "\n",
    "search = serpapi.search(params)\n",
    "results = search.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1afdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable JavaScript and cookies to continue\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://www.simplyhired.co.in/job/Mc598H9Z2FKtj893YIXzLDaynIcN2XJhfzF9qRQwhHbID3fYioiJ2A?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\", headers=headers)\n",
    "body = response.content\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "title = soup.title.string if soup.title else \"No title found\"\n",
    "text = \"\"\n",
    "if soup.body:\n",
    "    for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "        irrelevant.decompose()\n",
    "    text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "if \"sorry\" in text:\n",
    "    print(\"Job expired\")\n",
    "else:\n",
    "    print(text)\n",
    "# links = [link.get('href') for link in soup.find_all('a')]\n",
    "# self.links = [link for link in links if link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dac8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.simplyhired.co.in/job/Mc598H9Z2FKtj893YIXzLDaynIcN2XJhfzF9qRQwhHbID3fYioiJ2A?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\")  # Use the URL giving you trouble\n",
    "\n",
    "time.sleep(5)  # Give JS time to load\n",
    "html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236765d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title.string if soup.title else \"No title found\"\n",
    "text = \"\"\n",
    "if soup.body:\n",
    "    for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "        irrelevant.decompose()\n",
    "    text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "if \"sorry\" in text:\n",
    "    print(\"Job expired\")\n",
    "else:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdc076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
